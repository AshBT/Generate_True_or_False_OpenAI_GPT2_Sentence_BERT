{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate True or False questions from any content with OpenAI GPT2 text generation, Sentence-BERT semantic search and Berkley constituency parser.\n",
    "### Author: Ramsri Goutham (https://www.linkedin.com/in/ramsrig/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install sentence-transformers\n",
    "!pip install transformers==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install benepar\n",
    "!pip install summa\n",
    "!pip install nltk\n",
    "!pip install spacy==2.1.0\n",
    "!python3 -m spacy download en\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and download necessary files of NLTK and berkley constituency parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "2.6.0\n",
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print (torch.__version__)\n",
    "print (transformers.__version__)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package benepar_en2 to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package benepar_en2 is already up-to-date!\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from summa.summarizer import summarize\n",
    "import benepar\n",
    "import string\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from random import shuffle\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "#this package is required for the summa summarizer\n",
    "nltk.download('punkt')\n",
    "benepar.download('benepar_en2')\n",
    "benepar_parser = benepar.Parser(\"benepar_en2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load content from text file\n",
    "Load any chapter/story/content from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth’s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That’s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the “Pacific Ring of Fire.”\n"
     ]
    }
   ],
   "source": [
    "file_path = \"volcano.txt\" #other texts in same directory: \"PSLE.txt\", \"hellenkeller.txt\", \"Grade7_electricity.txt\" , \"material.txt\", \"paperboat.txt\"\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        return content\n",
    "    \n",
    "text = read_file(file_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the loaded content.\n",
    "Summarize the loaded content with summa extractive summarizer library. Also from the summarized sentences, remove sentences containing single quotes, double quotes and questions marks as they are not suitable for True or False Quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust\n",
      "\n",
      "\n",
      "Divergent plate boundaries also occur in the continental crust\n",
      "\n",
      "\n",
      "Volcanoes form at these boundaries, but less often than in ocean crust\n",
      "\n",
      "\n",
      "Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def preprocess(sentences):\n",
    "    output = []\n",
    "    for sent in sentences:\n",
    "        single_quotes_present = len(re.findall(r\"['][\\w\\s.:;,!?\\\\-]+[']\",sent))>0\n",
    "        double_quotes_present = len(re.findall(r'[\"][\\w\\s.:;,!?\\\\-]+[\"]',sent))>0\n",
    "        question_present = \"?\" in sent\n",
    "        if single_quotes_present or double_quotes_present or question_present :\n",
    "            continue\n",
    "        else:\n",
    "            output.append(sent.strip(punctuation))\n",
    "    return output\n",
    "        \n",
    "        \n",
    "def get_candidate_sents(resolved_text, ratio=0.3):\n",
    "    candidate_sents = summarize(resolved_text, ratio=ratio)\n",
    "    candidate_sents_list = tokenize.sent_tokenize(candidate_sents)\n",
    "    candidate_sents_list = [re.split(r'[:;]+',x)[0] for x in candidate_sents_list ]\n",
    "    # Remove very short sentences less than 30 characters and long sentences greater than 150 characters\n",
    "    filtered_list_short_sentences = [sent for sent in candidate_sents_list if len(sent)>30 and len(sent)<150]\n",
    "    return filtered_list_short_sentences\n",
    "\n",
    "cand_sents = get_candidate_sents(text)\n",
    "filter_quotes_and_questions = preprocess(cand_sents)\n",
    "for each_sentence in filter_quotes_and_questions:\n",
    "    print (each_sentence)\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split sentence at appropriate place with Berkley Constituency parser.\n",
    "Use Berkley Constituency parser to split a sentence at ending verb phrase or noun phrase.\n",
    "Eg : If the input sentence is **\"Divergent plate boundaries also occur in the continental crust\"**\n",
    "we split it at the ending noun phrase to get **\"Divergent plate boundaries also occur in\"**. Now we give the partial sentence **\"Divergent plate boundaries also occur in\"** to OpenAI GPT-2 to generate sentences with different endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust': ['As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in'], 'Divergent plate boundaries also occur in the continental crust': ['Divergent plate boundaries also occur in', 'Divergent plate boundaries also'], 'Volcanoes form at these boundaries, but less often than in ocean crust': ['Volcanoes form at these boundaries, but less often than in'], 'Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone': ['Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "def get_flattened(t):\n",
    "    sent_str_final = None\n",
    "    if t is not None:\n",
    "        sent_str = [\" \".join(x.leaves()) for x in list(t)]\n",
    "        sent_str_final = [\" \".join(sent_str)]\n",
    "        sent_str_final = sent_str_final[0]\n",
    "    return sent_str_final\n",
    "    \n",
    "\n",
    "def get_termination_portion(main_string,sub_string):\n",
    "    combined_sub_string = sub_string.replace(\" \",\"\")\n",
    "    main_string_list = main_string.split()\n",
    "    last_index = len(main_string_list)\n",
    "    for i in range(last_index):\n",
    "        check_string_list = main_string_list[i:]\n",
    "        check_string = \"\".join(check_string_list)\n",
    "        check_string = check_string.replace(\" \",\"\")\n",
    "        if check_string == combined_sub_string:\n",
    "            return \" \".join(main_string_list[:i])\n",
    "                     \n",
    "    return None\n",
    "    \n",
    "def get_right_most_VP_or_NP(parse_tree,last_NP = None,last_VP = None):\n",
    "    if len(parse_tree.leaves()) == 1:\n",
    "        return get_flattened(last_NP),get_flattened(last_VP)\n",
    "    last_subtree = parse_tree[-1]\n",
    "    if last_subtree.label() == \"NP\":\n",
    "        last_NP = last_subtree\n",
    "    elif last_subtree.label() == \"VP\":\n",
    "        last_VP = last_subtree\n",
    "    \n",
    "    return get_right_most_VP_or_NP(last_subtree,last_NP,last_VP)\n",
    "\n",
    "\n",
    "def get_sentence_completions(key_sentences):\n",
    "    sentence_completion_dict = {}\n",
    "    for individual_sentence in filter_quotes_and_questions:\n",
    "        sentence = individual_sentence.rstrip('?:!.,;')\n",
    "        tree = benepar_parser.parse(sentence)\n",
    "        last_nounphrase, last_verbphrase =  get_right_most_VP_or_NP(tree)\n",
    "        phrases= []\n",
    "        if last_verbphrase is not None:\n",
    "            verbphrase_string = get_termination_portion(sentence,last_verbphrase)\n",
    "            phrases.append(verbphrase_string)\n",
    "        if last_nounphrase is not None:\n",
    "            nounphrase_string = get_termination_portion(sentence,last_nounphrase)\n",
    "            phrases.append(nounphrase_string)\n",
    "\n",
    "        longest_phrase =  sorted(phrases, key=len,reverse= True)\n",
    "        if len(longest_phrase) == 2:\n",
    "            first_sent_len = len(longest_phrase[0].split())\n",
    "            second_sentence_len = len(longest_phrase[1].split())\n",
    "            if (first_sent_len - second_sentence_len) > 4:\n",
    "                del longest_phrase[1]\n",
    "                \n",
    "        if len(longest_phrase)>0:\n",
    "            sentence_completion_dict[sentence]=longest_phrase\n",
    "    return sentence_completion_dict\n",
    "\n",
    "\n",
    "\n",
    "sent_completion_dict = get_sentence_completions(filter_quotes_and_questions)\n",
    "\n",
    "print (sent_completion_dict)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OpenAI GPT2 and Sentence BERT.\n",
    "Use huggingface transformers library to generate text with OpenAI GPT-2 and sentence BERT for filtering similar generated sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/main_classes/model.html?highlight=no_repeat_ngram_size\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\",pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and \n",
    "# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md\n",
    "model_BERT = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter sentences and generate false sentences.\n",
    "Generate multiple sentences (OpenAI GPT2) and among them filter (Sentence BERT) the ones that are similar, since we want to keep only dissimilar ones as False sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**1) True Sentence (from the story) :**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "  **False Sentences (GPT-2 Generated)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**a)** As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust that provide access to oxygen-rich water."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**b)** As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the seafloor that are more sensitive to wind velocity and pressure than most continental surfaces."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**2) True Sentence (from the story) :**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Divergent plate boundaries also occur in the continental crust\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "  **False Sentences (GPT-2 Generated)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**a)** Divergent plate boundaries also occur in the low and high latitudes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**b)** Divergent plate boundaries also occur in regions with more frequent rainfall."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**c)** Divergent plate boundaries also occur in the brain of mammals and vertebrates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**d)** Divergent plate boundaries also have been proposed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**e)** Divergent plate boundaries also may be used to map and reduce traffic congestion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**f)** Divergent plate boundaries also had to be adjusted and the data collected from different cities was sent on a regular basis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**3) True Sentence (from the story) :**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Volcanoes form at these boundaries, but less often than in ocean crust\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "  **False Sentences (GPT-2 Generated)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**a)** Volcanoes form at these boundaries, but less often than in any other country,\" he says."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**b)** Volcanoes form at these boundaries, but less often than in a large coastal country (such as the USA) they must be found along well-defined water bodies such that their location can become clear."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**4) True Sentence (from the story) :**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "  **False Sentences (GPT-2 Generated)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**a)** Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a rate of 1.1, 3–4 km/h (5)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**b)** Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at about 25% of its original location."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**c)** Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a rate of about 100 million km/year."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import scipy\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "\n",
    "def sort_by_similarity(original_sentence,generated_sentences_list):\n",
    "    # Each sentence is encoded as a 1-D vector with 768 columns\n",
    "    sentence_embeddings = model_BERT.encode(generated_sentences_list)\n",
    "\n",
    "    queries = [original_sentence]\n",
    "    query_embeddings = model_BERT.encode(queries)\n",
    "    # Find the top sentences of the corpus for each query sentence based on cosine similarity\n",
    "    number_top_matches = len(generated_sentences_list)\n",
    "\n",
    "    dissimilar_sentences = []\n",
    "\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings, \"cosine\")[0]\n",
    "\n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "\n",
    "        for idx, distance in reversed(results[0:number_top_matches]):\n",
    "            score = 1-distance\n",
    "            if score < 0.9:\n",
    "                dissimilar_sentences.append(generated_sentences_list[idx].strip())\n",
    "           \n",
    "    sorted_dissimilar_sentences = sorted(dissimilar_sentences, key=len)\n",
    "    \n",
    "    return sorted_dissimilar_sentences[:3]\n",
    "    \n",
    "\n",
    "def generate_sentences(partial_sentence,full_sentence):\n",
    "    input_ids = torch.tensor([tokenizer.encode(partial_sentence)])\n",
    "    maximum_length = len(partial_sentence.split())+80\n",
    "\n",
    "    # Actiavte top_k sampling and top_p sampling with only from 90% most likely words\n",
    "    sample_outputs = model.generate(\n",
    "        input_ids, \n",
    "        do_sample=True, \n",
    "        max_length=maximum_length, \n",
    "        top_p=0.90, # 0.85 \n",
    "        top_k=50,   #0.30\n",
    "        repetition_penalty  = 10.0,\n",
    "        num_return_sequences=10\n",
    "    )\n",
    "    generated_sentences=[]\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        decoded_sentences = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "        decoded_sentences_list = tokenize.sent_tokenize(decoded_sentences)\n",
    "        generated_sentences.append(decoded_sentences_list[0])\n",
    "        \n",
    "    top_3_sentences = sort_by_similarity(full_sentence,generated_sentences)\n",
    "    \n",
    "    return top_3_sentences\n",
    "\n",
    "index = 1\n",
    "choice_list = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\"]\n",
    "for key_sentence in sent_completion_dict:\n",
    "    partial_sentences = sent_completion_dict[key_sentence]\n",
    "    false_sentences =[]\n",
    "    print_string = \"**%s) True Sentence (from the story) :**\"%(str(index))\n",
    "    printmd(print_string)\n",
    "    print (\"  \",key_sentence)\n",
    "    for partial_sent in partial_sentences:\n",
    "        false_sents = generate_sentences(partial_sent,key_sentence)\n",
    "        false_sentences.extend(false_sents)\n",
    "    printmd(\"  **False Sentences (GPT-2 Generated)**\")\n",
    "    for ind,false_sent in enumerate(false_sentences):\n",
    "        print_string_choices = \"**%s** %s\"%(choice_list[ind],false_sent)\n",
    "        printmd(print_string_choices)\n",
    "    index = index+1\n",
    "    \n",
    "    print (\"\\n\\n\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
